---
title: "Project 2: Unveiling Ecological Dynamics Through Simulation and Visualization of Biodiversity Data Cubes"
subtitle: "Setup and introduction"
author: "Ward Langeraert"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2:
    code_folding: hide
    toc: true
    toc_float: true
    toc_collapsed: true
editor_options: 
  chunk_output_type: console
---

```{r setup, message=FALSE, warning=FALSE}
# Setup
library(knitr)
library(here)
opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE)
opts_knit$set(root.dir = here())

# Packages
library(tidyverse)
```

# Introduction

Ecological systems are inherently variable, and a single dataset does not capture the full range of possible conditions. Simulations allow us to explore a broader spectrum of scenarios, considering different combinations of variables and their interactions. Ecological processes unfold dynamically over time, and a single snapshot of data does not capture the temporal aspects. Simulations enable the modelling of dynamic processes, allowing researchers to observe and analyse changes over various time scales.
 
As far as we know, there is no simulation framework present for biodiversity data cubes. A simulation framework in this context would help to examine the generalisability of the (statistical) properties of biodiversity data cubes and the derived indicators. 

# Technical setup and requirements

Download R, RStudio, git

Set up RStudio, git

Clone GitHub repository [hackathon-projects-2024](https://github.com/b-cubed-eu/hackathon-projects-2024) in RStudio.

pull changes

create branches

push changes

# Monte Carlo simulation framework for biodiversity data cubes

In this project, we will aim to create a simulation framework for biodiversity data cubes based on [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method). 

We need to simulate three different processes. 

1.  occurrence process
2.  detection process
3.  grid designation process

This is related to different variables that depend on *species*, *observation*, *space* and *time*.

In this project, we will focus on the occurrence and detection processes. For grid designation, R code is already available.

```{r processes-tab}
tibble(
  process = c(
    rep("occurrence", 2),
    rep("detection", 3)
  ),
  variable = c(
    "rarity",
    "spatial clustering",
    "detection probability",
    "sampling effort",
    "spatial uncertainty"
  ),
  dependency = c(
    "species, time",
    "species",
    "species",
    "space, time",
    "observation"
  )) %>%
  kable()
```

## Occurrence process

To simulate the occurrence of species in a certain spatial region, we need information on the rarity as well as a measure for spatial clustering.

### Rarity

-  Rarity can be different for each *species* and can change over *time*.
-  Values related to abundance/density
-  Implementation
   - Species: abundance/density for each species. Density can be converted to abundance based on the area of the polygon. Abundances can be generated from the Poisson distribution (`rpois()`)
   - Time: the order of random walk or a function (e.g. sinus, linear, exponential …)

```{r abundance-sim}
# Set seed for reproducibility
set.seed(123)

# Number of time points
n_time_points <- 50

# Time vector
time <- 1:n_time_points

# Sinusoidal trend parameters
amplitude <- 10
frequency <- 0.1

# Generate sinusoidal trend
sinusoidal_trend <- amplitude * sin(2 * pi * frequency * time)

# Poisson distribution parameters
lambda <- 100 - 1*time

# Number of simulations
n_sim <- 100
list_abundances <- vector("list", length = n_sim)

for (i in seq_len(n_sim)) {
  # Simulate abundances with Poisson distribution and sinusoidal trend
  abundances <- rpois(n_time_points, lambda + sinusoidal_trend)
  
  # Create a data frame
  list_abundances[[i]] <- data.frame(time = time, abundance = abundances,
                                     sim = i)
}
data_abundances <- do.call(rbind.data.frame, list_abundances)

# Plot the simulated abundances over time using ggplot2
ggplot(data_abundances, aes(x = time, y = abundance, colour = factor(sim))) +
  geom_line() +
  labs(x = "Time", y = "Species abundance",
       title = paste(n_sim, "simulated abundances with linear decreasing",
                     "sinusoidal trend over time")) +
  scale_y_continuous(limits = c(0, NA)) +
  theme_minimal() +
  theme(legend.position = "")
```

### Spatial clustering

-  Spatial clustering can be different for each *species*.
-  Values related to clustering ([Moran’s I](https://en.wikipedia.org/wiki/Moran%27s_I)? value between -1 (regular) to 0 (random) to 1 (clustered))
-  Implementation
   - Species: Get number of coordinate pairs based on clustering value equal to the abundance of the species.
   - Clustering value = Moran’s I? `runif(n, min = -1, max = 1)` for uniform distribution between -1 and 1 or the Beta distribution to get a skewed distribution between -1 and 1. Let $X \sim Beta(\alpha, \beta)$, then then the transformation $Y = 2X − 1$ will result in a distribution with values between -1 and 1.

```{r clustering-beta}
# Set seed for reproducibility
set.seed(123)

# Generate data
n <- 100
x_values <- seq(0, 1, length.out = n)

# Parameters Beta distribution
alpha <- c(0.5, 2, 2, 2, 7, 8)
beta <- c(0.5, 1, 2, 7, 2, 8)

# Calculate Beta densities in dataframe
clustering_df <- tibble(
  alpha = alpha,
  beta = beta) %>%
  expand(nesting(alpha, beta), x_values) %>%
  rowwise() %>%
  mutate(
    density = dbeta(x_values, shape1 = alpha, shape2 = beta),
    y_values = 2 * x_values - 1,
    distribution = paste0("Beta(", alpha, ",", beta, ")")
  )

# Plot the densities
ggplot(clustering_df, aes(x = y_values, y = density)) +
  geom_line() +
  labs(x = "Moran's I", y = "Density",
       title = "Densities of different Beta distributions") +
  facet_wrap(~distribution) +
  theme(legend.position = "") +
  theme_minimal()
```

## Detection process

To simulate the detection of individuals in a certain spatial region, we need information on the detection probability	of each species and sampling effort. The probability of detecting an individual can be the product of detection probability and sampling probability. Once observed, there is also always a certain spatial uncertainty related to each observation (`coordinateUncertaintyInMeters`).

### Detection probability
-  Detection probability can be different for each *species*.
-  Values are a probability between 0 (never detected) to 1 (always detected)
-  Implementation
   - Species: Probability between 0 and 1 for each species. `runif(n, min = 0, max = 1)` for uniform distribution between 0 and 1 or the Beta distribution to get a skewed distribution between -1 and 1.
   - See `detection.probability` argument in the `sampleOccurrences()` function of the **virtualspecies** package

```{r detection-beta}
# Set seed for reproducibility
set.seed(123)

# Generate data
n <- 100
x_values <- seq(0, 1, length.out = n)

# Parameters Beta distribution
alpha <- c(0.5, 2, 2, 2, 7, 8)
beta <- c(0.5, 1, 2, 7, 2, 8)

# Calculate densities in dataframe
detection_df <- tibble(
  alpha = alpha,
  beta = beta) %>%
  expand(nesting(alpha, beta), x_values) %>%
  rowwise() %>%
  mutate(
    density = dbeta(x_values, shape1 = alpha, shape2 = beta),
    distribution = paste0("Beta(", alpha, ",", beta, ")")
  )

# Plot the densities
ggplot(detection_df, aes(x = x_values, y = density)) +
  geom_line() +
  labs(x = "Detection probability", y = "Density",
       title = "Densities of different Beta distributions") +
  facet_wrap(~distribution) +
  theme(legend.position = "") +
  theme_minimal()
```

### Sampling effort

-  Sampling effort can be different in *space* and *time*.
-  Values are weights related to number of visits (?)
-  Implementation
   - Space: raster of bias weights to be applied to the sampling of occurrences. Higher weights mean a higher probability of sampling
   - Time: raster can be the same for each time period or differ
   - See `weights` argument in the `sampleOccurrences()` function of **virtualspecies** package

### Spatial uncertainty

-  Spatial uncertainty can be different for each *observation* or the same
-  Values are coordinate uncertainty in meters around observation
-  Implementation
   - Observation: distribution (uniform, (truncated) normal, gamma …) with varying upper bound, can be the same or different for all observations or something in between (extra parameter?)

```{r spat-uncertainty}
# Parameters for the truncated normal distribution
mean_val <- 20
sd_val <- 10

# Parameters for the Gamma distribution
shape <- 2
rate <- 0.1

# Set the lower limit for the truncated distributions
lower_limit <- 0

# Generate x values for the plot
x_values <- seq(lower_limit, mean_val + 5 * sd_val, length.out = 1000)

# Calculate the probability density function (PDF) for the positively truncated
# Normal distribution
density_values_normal <- dnorm(x_values, mean = mean_val, sd = sd_val)

# Calculate the probability density function (PDF) for the positively truncated
# Gamma distribution
density_values_gamma <- dgamma(x_values, shape = shape, rate = rate)

# Create a data frame
coord_uncertainty_df <- tibble(
  x = rep(x_values, 2),
  density = c(density_values_normal, density_values_gamma),
  distribution = rep(c(paste0("Normal", "(", mean_val, ",", sd_val, ")"),
                       paste0("Gamma", "(", shape, ",", rate, ")")),
                     each = length(x_values))
  )

# Plot the positive distributions
ggplot(coord_uncertainty_df, aes(x = x, y = density)) +
  geom_line() +
  labs(x = "Coordinate uncertainty in meters", y = "Density",
       title = "Positive distributions to sample spatial uncertainty") +
  facet_wrap(~distribution) +
  theme_minimal()
```

# Coding

Here are some ideas

-  a function for each process that can each contain multiple helper functions
-  each function simulates for 1 species, the user can easily simulate multiple species using loops,  `apply()` family functions, ...
-  as input we need a polygon to set the spatial extent or we could create a polygon based on X and Y coordinates given by the user?

```{r coding-tab}
tibble(
  process = c(
    rep("occurrence", 2),
    rep("detection", 3)
  ),
  variable = c(
    "rarity",
    "spatial clustering",
    "detection probability",
    "sampling effort",
    "spatial uncertainty"
  ),
  default = c(
    "rpois(1, rgamma(1, ?, ?)), where we only simulate for a single timepoint by default",
    "runif(n, min = -1, max = 1)",
    "1, all occurrences are detected",
    "NULL, default no difference in sampling effort",
    "25 meters?"
  )) %>%
  kable()
```

